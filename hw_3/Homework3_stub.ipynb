{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "301bf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "31cab31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "33f967ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3e25a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f88efc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a5f39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b3b16eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "09ac1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e4717806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c4a3ff82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('u67805239', 'b61372131', 4)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allRatings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ca3c2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b9bd53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.csv\", 'w')\n",
    "for l in open(\"pairs_Rating.csv\"):\n",
    "    if l.startswith(\"userID\"): # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',') # Read the user and item from the \"pairs\" file and write out your prediction\n",
    "    # (etc.)\n",
    "    \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "93959f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "abb17ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead/2: break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "80f40789",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7c9eea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books per user valid set: [('u59070515', {'b55084829'}), ('u05014036', {'b49553867'})]\n",
      "Users per book in all rating: [('b61372131', {'u01824015', 'u81545593', 'u10749976', 'u64965360', 'u69544334', 'u73816851', 'u58944461', 'u42850585', 'u39594275', 'u94503926', 'u30118092', 'u87998402', 'u63351603', 'u30806009', 'u95654536', 'u99062581', 'u82434460', 'u91947449', 'u38854826', 'u20491231', 'u51394014', 'u22497171', 'u89732246', 'u32610240', 'u46260999', 'u21325396', 'u03384038', 'u87366750', 'u26839529', 'u16132576', 'u79151084', 'u99811205', 'u36256752', 'u93815296', 'u48391630', 'u92278115', 'u98980325', 'u94309193', 'u18822429', 'u12983626', 'u62772540', 'u24156255', 'u80458214', 'u59157206', 'u71834505', 'u07240369', 'u47580089', 'u09441867', 'u20409355', 'u11499326', 'u26716074', 'u20496815', 'u62421718', 'u49555043', 'u43490914', 'u80993836', 'u53489985', 'u55760432', 'u34251370', 'u40248621', 'u84127839', 'u00111518', 'u11287990', 'u80414310', 'u54632797', 'u84677719', 'u35238062', 'u80108505', 'u93187835', 'u97896188', 'u39915694', 'u15273524', 'u09299901', 'u96486339', 'u94601424', 'u79693294', 'u72779856', 'u00942320', 'u07626684', 'u37485722', 'u70736453', 'u57025396', 'u13002014', 'u73104069', 'u61132304', 'u40018391', 'u21124433', 'u44294985', 'u93775605', 'u07219081', 'u96564934', 'u05243050', 'u93309829', 'u30715386', 'u87032002', 'u61897566', 'u33279275', 'u62994249', 'u39201986', 'u26130832', 'u07978766', 'u72002179', 'u52441700', 'u07077753', 'u86536075', 'u81456070', 'u38035670', 'u37384933', 'u49928458', 'u14287921', 'u45944018', 'u61307887', 'u73059201', 'u57167390', 'u11099702', 'u66765469', 'u16364343', 'u04346189', 'u79545859', 'u69458514', 'u28488526', 'u24245377', 'u87059406', 'u11621223', 'u90105683', 'u17054218', 'u01071398', 'u10186864', 'u47176135', 'u55040438', 'u39916505', 'u92688778', 'u28613373', 'u67652911', 'u02847996', 'u98143812', 'u77019266', 'u48667167', 'u34499606', 'u75158261', 'u46593302', 'u10094684', 'u51751023', 'u62443549', 'u60476786', 'u45796950', 'u06042879', 'u93455168', 'u38301742', 'u70632563', 'u32302727', 'u28788669', 'u53853048', 'u53518202', 'u05747014', 'u90080324', 'u28643897', 'u46738502', 'u66604369', 'u22116996', 'u02376300', 'u60413091', 'u89486150', 'u49798579', 'u52175326', 'u24054242', 'u53156902', 'u08830362', 'u23582351', 'u07706109', 'u02387553', 'u87623235', 'u72379291', 'u72768206', 'u89595017', 'u38576263', 'u55694722', 'u04867960', 'u87005946', 'u47340365', 'u73247015', 'u92511535', 'u93345803', 'u74972610', 'u17469822', 'u90994837', 'u60015993', 'u55940068', 'u17968157', 'u03804840', 'u32816001', 'u03241020', 'u52347798', 'u68350605', 'u69167162', 'u72346016', 'u80209244', 'u41779809', 'u26918913', 'u33561653', 'u90609631', 'u59180500', 'u95278557', 'u42959349', 'u15212012', 'u43462128', 'u50896822', 'u53536770', 'u34864333', 'u28242564', 'u61107512', 'u77573885', 'u72772985', 'u21013883', 'u46965119', 'u74026537', 'u76489507', 'u31140288', 'u45959946', 'u39779274', 'u93017626', 'u42487937', 'u57729910', 'u24627448', 'u69715416', 'u60761417', 'u03222960', 'u87542761', 'u24081627', 'u28393492', 'u19829762', 'u14736025', 'u41229670', 'u63369466', 'u58128495', 'u61269446', 'u70379269', 'u68551141', 'u14900242', 'u42317649', 'u52615516', 'u84104407', 'u35379244', 'u42737892', 'u86628952', 'u18890145', 'u10854286', 'u84517883', 'u32837451', 'u30529070', 'u18841473', 'u93089189', 'u48089762', 'u22721766', 'u68531514', 'u35109017', 'u69755750', 'u67181585', 'u87573336', 'u92909378', 'u50697764', 'u23816269', 'u87799062', 'u63965046', 'u09894186', 'u18848158', 'u13272452', 'u78225145', 'u10486680', 'u84509276', 'u36221021', 'u58883116', 'u03476667', 'u77737204', 'u36100138', 'u05235592', 'u89709107', 'u27524637', 'u45159912', 'u53021409', 'u44855451', 'u74239087', 'u54970112', 'u21716688', 'u77818953', 'u00394435', 'u44143300', 'u10931610', 'u58055472', 'u51174685', 'u71562608', 'u61366817', 'u29161853', 'u01100231', 'u34376327', 'u97027336', 'u92224973', 'u93245773', 'u83959085', 'u12798255', 'u04552848', 'u46611546', 'u78012510', 'u48513805', 'u92438328', 'u73425848', 'u06418798', 'u18351571', 'u05271717', 'u28332618', 'u38043397', 'u98576989', 'u06431119', 'u42425845', 'u15325951', 'u42144232', 'u92011368', 'u62261840', 'u50872015', 'u88246663', 'u28866517', 'u07199938', 'u93476362', 'u71442538', 'u99156633', 'u15845236', 'u64662977', 'u40783974', 'u82561004', 'u20490525', 'u07301204', 'u31156311', 'u48546840', 'u94849255', 'u11268268', 'u31311161', 'u77087319', 'u34293958', 'u70379483', 'u36300067', 'u76521824', 'u67805239', 'u29737522', 'u31770104', 'u21056033', 'u09618133', 'u63576642', 'u40376851', 'u83363542', 'u01465624', 'u49328949', 'u74280480', 'u55537243', 'u81363858', 'u15356321', 'u22387175', 'u63406049', 'u61326253', 'u94542033', 'u90702923', 'u54426184', 'u26486471', 'u62879061', 'u34508036', 'u81528217', 'u45373868', 'u09648034', 'u83896527', 'u56381530', 'u71724125', 'u41155507', 'u97321596', 'u39798574', 'u58633602', 'u33896303', 'u91590805', 'u17465739', 'u43474365', 'u91756228', 'u02612935', 'u15695801', 'u24875976', 'u15192312', 'u75035764', 'u86627282', 'u37067198', 'u78460875', 'u20576836', 'u51363556', 'u48572060', 'u41539938', 'u26129499', 'u74301010', 'u61395209', 'u49468556', 'u00614455', 'u75675518', 'u89898746', 'u27686873', 'u17796979', 'u35601774', 'u52785240', 'u69919217', 'u55163843', 'u56579723', 'u21385291', 'u11355430', 'u07687298', 'u62779369', 'u65030356', 'u44228858', 'u13836539', 'u05419797', 'u49766428', 'u92595296', 'u43951342', 'u36673967', 'u76366006', 'u44030786', 'u74302707', 'u01012215', 'u45862864', 'u50491431', 'u13701770', 'u20513462', 'u01463099', 'u57041384', 'u07085700', 'u24460410', 'u32191796', 'u07977672', 'u52874739', 'u08088480', 'u50590823', 'u34899198', 'u30759279', 'u15480196', 'u91289077', 'u07934198', 'u20901316', 'u74588676', 'u95030396', 'u87953963', 'u92313025', 'u57863489', 'u35388172', 'u86308891', 'u33197835', 'u41786010', 'u01106276', 'u69357820', 'u01638195', 'u21520589', 'u32166934', 'u93026622', 'u03379358', 'u07796423', 'u11915055', 'u52881301', 'u43616011', 'u79533904', 'u68108011', 'u03060272'}), ('b75189008', {'u20741612', 'u72852571', 'u77973877', 'u31795066', 'u22847065', 'u30317376', 'u54531895', 'u59520894', 'u90971268', 'u07501551'})]\n",
      "length of ratingValid: 10000\n",
      "booksPerUserValid length: 8142\n"
     ]
    }
   ],
   "source": [
    "booksPerUserValid = defaultdict(set)\n",
    "usersPerBookAllRatings = defaultdict(set)\n",
    "\n",
    "for u, b, r in allRatings:\n",
    "    # get sets of users that have read book\n",
    "    usersPerBookAllRatings[b].add(u)\n",
    "\n",
    "# get set of books from ALL RATINGS\n",
    "set_of_books = set([b for b in usersPerBookAllRatings])\n",
    "\n",
    "\n",
    "for d in ratingsValid:\n",
    "    # get sets of books for each user that they've read\n",
    "    booksPerUserValid[d[0]].add(d[1])\n",
    "\n",
    "print(f\"books per user valid set: {[(u, books) for ind, (u, books) in enumerate(booksPerUserValid.items()) if ind < 2]}\")\n",
    "print(f\"Users per book in all rating: {[(b, users) for ind, (b, users) in enumerate(usersPerBookAllRatings.items()) if ind < 2]}\")\n",
    "print(f\"length of ratingValid: {len(ratingsValid)}\")\n",
    "print(f\"booksPerUserValid length: {len(booksPerUserValid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cacee08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List (user, book) entries of unread books by user: [('u59070515', 'b08643931'), ('u05014036', 'b78420438')]\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "notRead_valid_set = []\n",
    "\n",
    "for d in ratingsValid:\n",
    "    # get the books that user have not read\n",
    "    diff = set_of_books.difference(booksPerUserValid[d[0]])\n",
    "\n",
    "    # add not_read books to existing validation set \n",
    "    notRead_valid_set.append((d[0], list(diff)[random.randint(0, len(diff)-1)]))\n",
    "    # notRead_valid_set[d[0]].append(list(diff)[random.randint(0, len(diff)-1)]) # get random book for user\n",
    "\n",
    "\n",
    "print(f\"List (user, book) entries of unread books by user: {[(u, book) for ind, (u, book) in enumerate(notRead_valid_set) if ind < 2]}\")\n",
    "print(len(notRead_valid_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e8d7724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before length: 10000\n",
      "after length: 20000\n"
     ]
    }
   ],
   "source": [
    "# adding to current validation set\n",
    "print(f\"before length: {len(ratingsValid)}\")\n",
    "ratingsValid_q1 = ratingsValid\n",
    "for u, b in notRead_valid_set:\n",
    "    ratingsValid_q1.append((u,b))\n",
    "\n",
    "print(f\"after length: {len(ratingsValid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8c420317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71105\n"
     ]
    }
   ],
   "source": [
    "def accuracy(pred, y):\n",
    "    TP_ = numpy.logical_and(pred, y)\n",
    "    FP_ = numpy.logical_and(pred, numpy.logical_not(y))\n",
    "    TN_ = numpy.logical_and(numpy.logical_not(pred), numpy.logical_not(y))\n",
    "    FN_ = numpy.logical_and(numpy.logical_not(pred), y)\n",
    "\n",
    "    TP = sum(TP_)\n",
    "    FP = sum(FP_)\n",
    "    TN = sum(TN_)\n",
    "    FN = sum(FN_)\n",
    "\n",
    "    acc = (TP + TN)/len(pred)\n",
    "    return acc\n",
    "\n",
    "# Evaluate performance of baseline model on validation set\n",
    "y_q1 = [1]*10000 + [0]*10000\n",
    "ypred_q1 = []\n",
    "count_exist = 0\n",
    "for d in ratingsValid_q1:\n",
    "    if d[1] in return1:\n",
    "        ypred_q1.append(1)\n",
    "    else:\n",
    "        ypred_q1.append(0)\n",
    "\n",
    "acc1 = accuracy(ypred_q1, y_q1)\n",
    "print(acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8af7b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6839df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "50491907",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "87e03b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset rating valid and other data sets\n",
    "# ratingsTrain = allRatings[:190000]\n",
    "# ratingsValid = allRatings[190000:]\n",
    "# ratingsPerUser = defaultdict(list)\n",
    "# ratingsPerItem = defaultdict(list)\n",
    "# for u, b, r in ratingsTrain:\n",
    "#     ratingsPerUser[u].append((b, r))\n",
    "#     ratingsPerItem[b].append((u, r))\n",
    "\n",
    "# add \n",
    "\n",
    "acc2 = 0\n",
    "threshold = 2\n",
    "for thres in [0.05*r for r in range(1, 20)]:\n",
    "    return2 = set()\n",
    "    count_q2 = 0\n",
    "    ypred_q2 = []\n",
    "    for ic, i in mostPopular:\n",
    "        count_q2 += ic\n",
    "        return2.add(i)\n",
    "        if count_q2 > totalRead*thres: break\n",
    "    for d in ratingsValid:\n",
    "        if d[1] in return2:\n",
    "            ypred_q2.append(1)\n",
    "        else:\n",
    "            ypred_q2.append(0)\n",
    "    curr_acc = accuracy(ypred_q2, y_q1)\n",
    "    if curr_acc > acc2:\n",
    "        acc2 = curr_acc\n",
    "        threshold = thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "263c16a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.75375\n"
     ]
    }
   ],
   "source": [
    "answers['Q2'] = [threshold, acc2]\n",
    "print(threshold)\n",
    "print(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fcb6b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q2'][0])\n",
    "assertFloat(answers['Q2'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5612c849",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b753559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "04a6f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numerator = len(s1.intersection(s2))\n",
    "    denominator = len(s1.union(s2))\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    return numerator/denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1a422124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up data structures from training and validation data\n",
    "\n",
    "booksPerUser_train = defaultdict(set)\n",
    "booksPerUser_valid = defaultdict(set)\n",
    "usersPerBook_train = defaultdict(set)\n",
    "usersPerBook_valid = defaultdict(set)\n",
    "\n",
    "for u, b, r in ratingsTrain:\n",
    "    booksPerUser_train[u].add(b)\n",
    "    usersPerBook_train[b].add(u)\n",
    "\n",
    "for d in ratingsValid:\n",
    "    booksPerUser_valid[d[0]].add(d[1])\n",
    "    usersPerBook_valid[d[1]].add(d[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9971fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for b in usersPerBook_valid:\n",
    "#     sim = Jaccard(usersPerBook_train[u], usersPerBook_valid[u])\n",
    "#     if sim > 0.5:\n",
    "#         pass\n",
    "acc3 = 0 \n",
    "ypred_q3 = []\n",
    "for d in ratingsValid:\n",
    "    # get similaritiy for all pairs in validation set\n",
    "    max_sim = 0                                                  # d[1] = b' = books from training set\n",
    "    for b in booksPerUser_train[d[0]]:\n",
    "        if b == d[1]: continue                                  # b = books from validation set, using the user in validation set\n",
    "        sim = Jaccard(usersPerBook_train[b], usersPerBook_train[d[1]])  # compute jaccard similarity between users in train for books in validation set and training set\n",
    "        if max_sim < sim:\n",
    "            max_sim = sim\n",
    "    if max_sim > 0:\n",
    "        ypred_q3.append(1)\n",
    "    else:\n",
    "        ypred_q3.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "abdaaeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6823\n"
     ]
    }
   ],
   "source": [
    "acc3 = accuracy(ypred_q3, y_q1)\n",
    "print(acc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09fd07e",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "53b8b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_q4 = 0\n",
    "return_q4 = set()\n",
    "for ic, i in mostPopular:\n",
    "    count_q4 += ic\n",
    "    return_q4.add(i)\n",
    "    if count_q4 > totalRead*0.75:           # threshold from Q2\n",
    "        break\n",
    "\n",
    "ypred_q4 = []\n",
    "for d in ratingsValid:\n",
    "    # get similaritiy for all pairs in validation set\n",
    "    # d[1] = b' = books from training set\n",
    "    max_sim = 0\n",
    "    for b in booksPerUser_train[d[0]]:\n",
    "        if b == d[1]:\n",
    "            # b = books from validation set, using the user in validation set\n",
    "            continue\n",
    "        # compute jaccard similarity between users in train for books in validation set and training set\n",
    "        sim = Jaccard(usersPerBook_train[b], usersPerBook_train[d[1]])\n",
    "        if max_sim < sim:\n",
    "            max_sim = sim\n",
    "    if max_sim > 0 and d[1] in return_q4:\n",
    "        ypred_q4.append(1)\n",
    "    else:\n",
    "        ypred_q4.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "912649c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc4 = accuracy(ypred_q4, y_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "83ab0986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc3: 0.6823\n",
      "acc4: 0.74295\n"
     ]
    }
   ],
   "source": [
    "answers['Q3'] = acc3\n",
    "answers['Q4'] = acc4\n",
    "print(f\"acc3: {acc3}\")\n",
    "print(f\"acc4: {acc4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fbdd0c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q3'])\n",
    "assertFloat(answers['Q4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3e68cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.csv\", 'w')\n",
    "for l in open(\"pairs_Read.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "    max_sim = 0\n",
    "    for b2 in booksPerUser_train[u]:\n",
    "        if b2 == b:\n",
    "            # b = books from validation set, using the user in validation set\n",
    "            continue\n",
    "        # compute jaccard similarity between users in train for books in validation set and training set\n",
    "        sim = Jaccard(usersPerBook_train[b2], usersPerBook_train[b])\n",
    "        if max_sim < sim:\n",
    "            max_sim = sim\n",
    "    if max_sim > 0 and b in return_q4:\n",
    "       predictions.write(u + ',' + b + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + ',' + b + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "297b5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = \"I confirm that I have uploaded an assignment submission to gradescope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b3cb95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(answers['Q5']) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d87b97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Category prediction (CSE158 only)              #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "84cdc447",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2bf8b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for d in readGz(\"train_Category.json.gz\"):\n",
    "    data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a696b146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 'u75242413',\n",
       " 'review_id': 'r45843137',\n",
       " 'rating': 4,\n",
       " 'review_text': \"a clever book with a deeply troubling premise and an intriguing protagonist. Thompson's clean, sparse prose style kept each page feeling light even as some rather heavy existential questions dropped upon them. I enjoyed it. \\n and that cover design is boom-pow gorgeous.\",\n",
       " 'n_votes': 1,\n",
       " 'genre': 'mystery_thriller_crime',\n",
       " 'genreID': 3}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b0d014ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_all_data = [d for d in data]\n",
    "category_train_data = category_all_data[:90000]\n",
    "category_valid_data = category_all_data[90000:]\n",
    "\n",
    "wordCount_train_q6 = defaultdict(int)\n",
    "totalWords = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dc44cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct  = string.punctuation\n",
    "# stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1c18a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique words and its counts\n",
    "for d in category_train_data:\n",
    "    rev:string = d['review_text']\n",
    "    rev = rev.lower()\n",
    "    rev = [c for c in rev if not (c in punct)]\n",
    "    rev = ''.join(rev)\n",
    "    words = rev.strip().split()\n",
    "    for w in words:\n",
    "        wordCount_train_q6[w] += 1\n",
    "        totalWords += 1\n",
    "\n",
    "# get the top 1000 most common words\n",
    "counts_q6 = [(wordCount_train_q6[w], w) for w in wordCount_train_q6]\n",
    "counts_q6.sort()\n",
    "counts_q6.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "59d6e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = counts_q6[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f73d9e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [type(x[0]) for x in answers['Q6']] == [int]*10\n",
    "assert [type(x[1]) for x in answers['Q6']] == [str]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7e4cc861",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c97fc468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 1000 unique words \n",
    "common1000 = [w for count, w in counts_q6[:1000]]\n",
    "wordId_q7 = dict(zip(common1000, range(len(common1000))))\n",
    "word_set_q7 = set(common1000) # build dictionary\n",
    "len(word_set_q7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ce6618c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 2, 0, 0, 0, 1, 0, 1, 0]\n",
      "[3, 1, 4, 2, 2, 4, 2, 0, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "# iterate through entire dataset and count number of top 1000 unique words per review\n",
    "def feature(datum):\n",
    "    # Iterate through a review at a time\n",
    "    feat = [0]*len(word_set_q7)\n",
    "    rev = datum['review_text']\n",
    "    rev = [c for c in rev if not (c in punct)]\n",
    "    rev = ''.join(rev)\n",
    "    words = rev.strip().split()\n",
    "    for w in words:\n",
    "        # check each word in review\n",
    "        if not (w in word_set_q7): continue\n",
    "        feat[wordId_q7[w]] += 1\n",
    "    feat.append(1)                          # constant \n",
    "    return feat\n",
    "\n",
    "X_q7 = [feature(d) for d in data] # a list_a of list_b. len(X) = len(y)\n",
    "y = [d['genreID'] for d in data]\n",
    "\n",
    "print(X_q7[0][:10])\n",
    "print(y[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4b717508",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_q7train = X_q7[:9*len(X_q7)//10]\n",
    "ytrain = y[:9*len(y)//10]\n",
    "X_q7valid = X_q7[9*len(X_q7)//10:]\n",
    "yvalid = y[9*len(y)//10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "acec533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(C=1.0)\n",
    "model.fit(X_q7train, ytrain)\n",
    "ypred_valid_q7 = model.predict(X_q7valid)\n",
    "\n",
    "acc7 = accuracy(yvalid, ypred_valid_q7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7f1d72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9344\n"
     ]
    }
   ],
   "source": [
    "answers['Q7'] = acc7\n",
    "print(acc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "127355fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "152d93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9d512089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc8: 0.9361\n",
      "c: 0.01\n"
     ]
    }
   ],
   "source": [
    "acc8 = acc7\n",
    "for c in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "    model_q8 = linear_model.LogisticRegression(C=c)\n",
    "    model_q8.fit(X_q7train, ytrain)\n",
    "    ypred_valid_q8 = model_q8.predict(X_q7valid)\n",
    "    curr_acc = accuracy(yvalid, ypred_valid_q8)\n",
    "    if curr_acc > acc8:\n",
    "        acc8 = curr_acc\n",
    "        print(f\"acc8: {acc8}\")\n",
    "        print(f\"c: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0cf9af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature(datum, common_words, word_set):\n",
    "#     # Iterate through a review at a time\n",
    "#     feat = [0]*len(word_set_q7)\n",
    "#     rev = datum['review_text']\n",
    "#     rev = [c for c in rev if not (c in punct)]\n",
    "#     rev = ''.join(rev)\n",
    "#     words = rev.strip().split()\n",
    "#     for w in common1000:\n",
    "#         # check each word in review\n",
    "#         if not (w in word_set_q7):\n",
    "#             continue\n",
    "#         feat[wordId_q7[w]] += 1\n",
    "#     feat.append(1)                          # constant\n",
    "#     return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9edb7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [2000, 3000, 4000, 5000, 6000]:\n",
    "#     # get top {size} unique words\n",
    "#     common_words = [w for count, w in counts_q6[:size]]\n",
    "#     wordId_q8 = dict(zip(common_words, range(len(common_words))))\n",
    "#     word_set_q8 = set(common_words)  # build dictionary\n",
    "#     len(word_set_q7)\n",
    "#     for \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e3913bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9361\n"
     ]
    }
   ],
   "source": [
    "answers['Q8'] = acc8\n",
    "print(acc8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a3dc3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f77dc611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "062acd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model_submission = linear_model.LogisticRegression(C=0.01)\n",
    "model_submission.fit(X_q7train, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "67cebc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 'u77355739', 'review_id': 'r70788666', 'rating': 4, 'review_text': \"love it \\n it's that kind of crime-mystery novel that anyone can : read , love and understand . \\n my favorite part is in the first chapter when Mr. quin help the old man( i forget his name) to solve a long time closed mystery , and that is only the beginning\", 'n_votes': 0}\n"
     ]
    }
   ],
   "source": [
    "data_cat = []\n",
    "\n",
    "for d in readGz(\"test_Category.json.gz\"):\n",
    "    data_cat.append(d)\n",
    "\n",
    "print(data_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3fc664fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewID= defaultdict(set)\n",
    "genreCount = defaultdict(int)\n",
    "genreIDtoGenre = defaultdict(int)\n",
    "for d in data_cat:\n",
    "    reviewID[d['review_id']] = d\n",
    "\n",
    "for d in data:\n",
    "    genreCount[d['genre']] += 1\n",
    "    genreIDtoGenre[d['genreID']] = d['genre']\n",
    "\n",
    "reviewId_list = [r_id for r_id in reviewID]\n",
    "genre_list = [(count, genre) for genre, count in genreCount.items()]\n",
    "genre_list.sort()\n",
    "genre_list.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e2f18b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Category.csv\", 'w')\n",
    "pos = 0\n",
    "\n",
    "for l in open(\"pairs_Category.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "    if b in reviewId_list:\n",
    "        X_submission = [feature(reviewID[b])]\n",
    "        ypred_submit = model_submission.predict(X_submission)\n",
    "        predictions.write(f\"{u},{b},{genreIDtoGenre[ypred_submit[0]]}\\n\")\n",
    "    else:\n",
    "        predictions.write(f\"{u},{b},{genre_list[0][1]}\\n\")\n",
    "        print(\"not a known review\")\n",
    "    \n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "839261ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw3.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000bdde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1274fbf3fb2acb349aaf0edcc2132b005d389f6cbaae11e6f28d92603912a4a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
