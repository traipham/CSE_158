{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dbcb905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import gzip\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94e03340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bbbc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85c00feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"5year.arff\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6fad4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and parse the data\n",
    "while not '@data' in f.readline():\n",
    "    pass\n",
    "\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if '?' in l: # Missing entry\n",
    "        continue\n",
    "    l = l.split(',')\n",
    "    values = [1] + [float(x) for x in l]\n",
    "    values[-1] = values[-1] > 0 # Convert to bool\n",
    "    dataset.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7691e3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031\n",
      "3031\n"
     ]
    }
   ],
   "source": [
    "X = [d[:-1] for d in dataset]\n",
    "y = [d[-1] for d in dataset]\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03249990",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {} # Your answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a31a5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, y):\n",
    "    TP_ = numpy.logical_and(pred, y)\n",
    "    FP_ = numpy.logical_and(pred, numpy.logical_not(y))\n",
    "    TN_ = numpy.logical_and(numpy.logical_not(pred), numpy.logical_not(y))\n",
    "    FN_ = numpy.logical_and(numpy.logical_not(pred), y)\n",
    "\n",
    "    TP = sum(TP_)\n",
    "    FP = sum(FP_)\n",
    "    TN = sum(TN_)\n",
    "    FN = sum(FN_)\n",
    "\n",
    "    acc = (TP + TN)/len(pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83974166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BER(pred, y):\n",
    "    \"\"\"Evaluate Balanced Error rate of prediction and true values\"\"\"\n",
    "    TP_ = numpy.logical_and(pred, y)\n",
    "    FP_ = numpy.logical_and(pred, numpy.logical_not(y))\n",
    "    TN_ = numpy.logical_and(numpy.logical_not(pred), numpy.logical_not(y))\n",
    "    FN_ = numpy.logical_and(numpy.logical_not(pred), y)\n",
    "\n",
    "    TP = sum(TP_)\n",
    "    FP = sum(FP_)\n",
    "    TN = sum(TN_)\n",
    "    FN = sum(FN_)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "\n",
    "    BER = 1 - (0.5*(TPR + TNR))\n",
    "    return BER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e78a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f59633dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(C=1)\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b1ab401",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1 = accuracy(pred, y)\n",
    "ber1 = BER(pred, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "033a6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = [acc1, ber1] # Accuracy and balanced error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e75988a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q1'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "30482ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc8f8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(C=1, class_weight='balanced')\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e99274d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2 = accuracy(pred, y)\n",
    "ber2 = BER(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de8d6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [acc2, ber2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a90cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q2'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1fa1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55d4beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(3)\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d19c0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [d[:-1] for d in dataset]\n",
    "y = [d[-1] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "18d5fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6d66f07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515, 758, 758)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtrain), len(Xvalid), len(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "647021ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(C=1, class_weight='balanced')\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2b4fcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(Xtrain)\n",
    "pred_valid = model.predict(Xvalid)\n",
    "pred_test = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "703d5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "berTrain = BER(pred_train, ytrain)\n",
    "berValid = BER(pred_valid, yvalid)\n",
    "berTest = BER(pred_test, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0bb40dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = [berTrain, berValid, berTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e0ece86",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q3'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "81d44cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb5200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "964c691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(X, y, c, data_set):\n",
    "    \"\"\"Make a prediction using different regularization coefficients\"\"\"\n",
    "    model = linear_model.LogisticRegression(C=c, class_weight='balanced')\n",
    "    model.fit(X, y)\n",
    "\n",
    "    pred = model.predict(data_set)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ff0daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_n10000 = make_pred(Xtrain, ytrain, c=10**-4, data_set=Xvalid)\n",
    "pred_n1000 = make_pred(Xtrain, ytrain, c=10**-3, data_set=Xvalid)\n",
    "pred_n100 = make_pred(Xtrain, ytrain, c=10**-2, data_set=Xvalid)\n",
    "pred_n10 = make_pred(Xtrain, ytrain, c=10**-1, data_set=Xvalid)\n",
    "pred_1 = make_pred(Xtrain, ytrain, c=1, data_set=Xvalid)\n",
    "pred_10 = make_pred(Xtrain, ytrain, c=10, data_set=Xvalid)\n",
    "pred_100 = make_pred(Xtrain, ytrain, c=10**2, data_set=Xvalid)\n",
    "pred_1000 = make_pred(Xtrain, ytrain, c=10**3, data_set=Xvalid)\n",
    "pred_10000 = make_pred(Xtrain, ytrain, c=10**4, data_set=Xvalid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3c0a8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "BER_n10000 = BER(pred_n10000, yvalid)\n",
    "BER_n1000 = BER(pred_n1000, yvalid)\n",
    "BER_n100 = BER(pred_n100, yvalid)\n",
    "BER_n10 = BER(pred_n10, yvalid)\n",
    "BER_1 = BER(pred_1, yvalid)\n",
    "BER_10 = BER(pred_10, yvalid)\n",
    "BER_100 = BER(pred_100, yvalid)\n",
    "BER_1000 = BER(pred_1000, yvalid)\n",
    "BER_10000 = BER(pred_10000, yvalid)\n",
    "\n",
    "berList = [BER_n10000, BER_n1000, BER_n100,\n",
    "           BER_n10, BER_1, BER_10, BER_100, BER_1000, BER_10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c96b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = berList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f55f3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q4'], 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b455b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2a80d25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3288104929895974, 0.31931252826775225, 0.3301673450927183, 0.3179556761646314, 0.3159203980099503, 0.3111714156490276, 0.2955030044582283, 0.29618143050978873, 0.29618143050978873]\n",
      "0.2955030044582283\n"
     ]
    }
   ],
   "source": [
    "# check for lowest BER from the regularization pipeline \n",
    "print(berList)\n",
    "print(min(berList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "88fbe9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C at index: 6\n",
      "Best C: 100\n"
     ]
    }
   ],
   "source": [
    "c_s = [10**-4, 10**-3, 10**-2, 10**-1, 1, 10, 10**2, 10**3, 10**4] # list of regularization coefficients\n",
    "best_c_ind= berList.index(min(berList))\n",
    "bestC = c_s[best_c_ind] \n",
    "\n",
    "print(f\"Best C at index: {best_c_ind}\")\n",
    "print(f\"Best C: {bestC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "91e03c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred = make_pred(Xtrain, ytrain, bestC, Xtest) # create model with the best C value(smallest BER) and test data\n",
    "ber5 = BER(best_pred, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "62bdaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = [bestC, ber5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b8cafe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q5'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fcbc2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ace19c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(\"young_adult_10000.json.gz\")\n",
    "dataset = []\n",
    "for l in f:\n",
    "    dataset.append(eval(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "06598b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': '8842281e1d1347389f2ab93d60773d4d', 'book_id': '2767052', 'review_id': '248c011811e945eca861b5c31a549291', 'rating': 5, 'review_text': \"I cracked and finally picked this up. Very enjoyable quick read - couldn't put it down - it was like crack. \\n I'm a bit bothered by the lack of backstory of how Panem and the Hunger Games come about. It is just kind of explained away in a few paragraphs and we are left to accept this very strange world where teenagers are pitted into an arena each year to kill each other? I was expecting it because I've seen Battle Royale, but I would have appreciated knowing more of the backstory of how the world could have come into such a odd state. \\n I suppose what makes a book like this interesting is thinking about the strategy of it all. The players are going to be statistically encouraged to band together because they will last longer that way, but by definition of course any partnership will be broken, and the drama of how that unfolds is always interesting and full of friendships broken and betrayal. Each character approached the game in their own way. Some banded together in larger coalitions, some were loners initially and banded together later. And some were just loners, like Foxface. A lot depended on your survival skill: could you find food and water on your own? Self-dependence is highly valued - and of course our hero was strong there. \\n All in all, a fun read, but I feel kind of dirty for having read it.\", 'date_added': 'Wed Jan 13 13:38:25 -0800 2010', 'date_updated': 'Wed Mar 22 11:46:36 -0700 2017', 'read_at': 'Sun Mar 25 00:00:00 -0700 2012', 'started_at': 'Fri Mar 23 00:00:00 -0700 2012', 'n_votes': 24, 'n_comments': 25}\n"
     ]
    }
   ],
   "source": [
    "dataTrain = dataset[:9000]\n",
    "dataTest = dataset[9000:]\n",
    "\n",
    "print(dataTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4209458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures you might want\n",
    "\n",
    "usersPerItem = defaultdict(set) # Maps an item to the users who rated it\n",
    "itemsPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "ratingDict = {} # To retrieve a rating for a specific user/item pair\n",
    "\n",
    "for d in dataTrain:\n",
    "    user = d['user_id']\n",
    "    item = d['book_id']\n",
    "    review = d['review_id']\n",
    "    rating = d['rating']\n",
    "    usersPerItem[item].add(user) # for each item, there is a set of users that gave a rating\n",
    "    itemsPerUser[user].add(item) # for each user, there is a set of items they've rated\n",
    "    reviewsPerUser[user].append(d) # for each user, there is a list of reviews the user made\n",
    "    reviewsPerItem[item].append(d) # for each item, there is a list of reviews that was made for item\n",
    "    ratingDict[(user, item)] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03c90f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numerator = len(s1.intersection(s2))\n",
    "    denominator = len(s1.union(s2))\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "25bfacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(i, N=10):\n",
    "    similarities = []        # list of (Jaccard_similarity, item) pair\n",
    "    users =  usersPerItem[i] # list of users that rated item i \n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2]) # compare item that we're looking at to other items, to see if same user have rated it \n",
    "        similarities.append((sim, i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    \n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2652a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = mostSimilar('2767052', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "35457af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q6']) == 10\n",
    "assertFloatList([x[0] for x in answers['Q6']], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "69798ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "68065730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def avg_user_rating(user):\n",
    "#     ratings = []\n",
    "#     for rev in reviewsPerUser[user]:\n",
    "#         ratings.append(rev['rating'])\n",
    "#     if len(ratings) > 0:\n",
    "#         avg_rating = sum(ratings)/len(ratings)\n",
    "#         return avg_rating\n",
    "#     return 0\n",
    "\n",
    "def avg_item_rating(item):\n",
    "    \"\"\"Get the average rating of an item\"\"\"\n",
    "    ratings = []\n",
    "    for rev in reviewsPerItem[item]:\n",
    "        ratings.append(rev['rating'])\n",
    "\n",
    "    if len(ratings) > 0:\n",
    "        avg_rating = sum(ratings)/len(ratings)\n",
    "        return avg_rating\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "25e6f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predRating(user, item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in  reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if item == i2: continue\n",
    "        ratings.append(d['rating'] - (avg_item_rating(i2)))                # subtract by the average rating for regularization purposes\n",
    "        similarities.append(Jaccard(usersPerItem[item], usersPerItem[i2])) # Use Jaccard similaritiy to find similarity between items\n",
    "    if sum(similarities) > 0:\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings, similarities)]\n",
    "        return avg_item_rating(item) + sum(weightedRatings) / sum(similarities)     # uses the form of function presented in Q7\n",
    "    else:\n",
    "        return sum([d['rating'] for d in dataset]) / len(dataset)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f22c17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = 0\n",
    "for d in dataTest:\n",
    "    sse += (d['rating']-predRating(d['user_id'], d['book_id']))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse7 = sse/len(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = mse7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d294f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781abe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predRatingByUser(user, item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in  reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        u2 = d['user_id']\n",
    "        if user == u2: continue\n",
    "        ratings.append(d['rating'] - (avg_item_rating(i2)))\n",
    "        similarities.append(Jaccard(itemsPerUser[user], itemsPerUser[u2]))      # USe Jaccard to get similarities between set of items that user rated compared to u2\n",
    "    if sum(similarities) > 0:\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings, similarities)]\n",
    "        return avg_item_rating(item) + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        return sum([d['rating'] for d in dataset]) / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114db2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = 0\n",
    "for d in dataTest:\n",
    "    sse += (d['rating']-predRatingByUser(d['user_id'], d['book_id']))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse8 = sse/len(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = mse8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def088ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw2.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb717703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0764f48b755a8f182461d98d02b99c4c6a349b0b4f134bbd04c9a103f720b18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
